{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Mateus Marinheiro\n",
    "\n",
    "Nome: Henrique Albuquerque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Mateus Marinhero\\Documents\\Insper\\2023\\2o Semestre\\Ciência dos Dados\\Projeto1\\Projeto-1-C-Dados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fique atento na compra. Ainda está com problem...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Talvez a tradução antiga tivesse um pouco mais...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sinceramente, também estou tentando entender c...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Escolhi o livro por acreditar no tema e indica...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recebi o produto avariado, no mesmo dia reclam...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem       Target\n",
       "0  Fique atento na compra. Ainda está com problem...    Relevante\n",
       "1  Talvez a tradução antiga tivesse um pouco mais...    Relevante\n",
       "2  Sinceramente, também estou tentando entender c...    Relevante\n",
       "3  Escolhi o livro por acreditar no tema e indica...  Irrelevante\n",
       "4  Recebi o produto avariado, no mesmo dia reclam...    Relevante"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante    153\n",
       "Relevante      147\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Não sou de desistir de livro, mas neste não te...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tao ruim quanto o primeiro. Fonte não justific...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sou fã do canal, estava na primeira sessão da ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Péssimo. O autor claramente tem um visão disto...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem       Target\n",
       "0  Não sou de desistir de livro, mas neste não te...  Irrelevante\n",
       "1  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...    Relevante\n",
       "2  Tao ruim quanto o primeiro. Fonte não justific...    Relevante\n",
       "3  Sou fã do canal, estava na primeira sessão da ...  Irrelevante\n",
       "4  Péssimo. O autor claramente tem um visão disto...  Irrelevante"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante    162\n",
       "Relevante       38\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de feedbacks de produtos da Amazon\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será criado um classificador segundo a teoria de probabilidade de Naïve Bayes, classificando notícias atuais sobre o mercado digital como:\n",
    "\n",
    "- Relevante: Mensagens consideradas como relevantes serão aqueles que trazem alguma crítica à direcionadas a Amazon, sejam elas, em relação à preços, envios e outros problemas. Também serão considerados relevantes críticas feitas às editoras, sendo assim, mensagens criticando a tradução, formatação do texto, qualidade do produto entre outros.</li>\n",
    "    \n",
    "- Irrelevante: Mensagens consideradas como Irrelevantes serão aquelas que trazem qualquer tipo de opinião sobre o livro, qualquer tipo de elogio e qualquer outra coisa que não se enquadra como relevante.  </li>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Funções de  _cleanup_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que irá retirar das mensagens recebidas todos os ruídos, sendo eles, pountuações e símbolos, emojis e números, que foram considerados irrelevantes para o nosso classificador. Visto que eles não agregam nenhum significado que irá trazer características de alguma das duas classe estabelecidas préviamente, visto que são caracteres que são utilizadas em grande escala, contendo diversas maneiras de serem usados em diversos casos, como as pontuações e os números, ou então, são utilizados raramente e não agregam nenhum sentido para a mensagem, como os emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[´\"!-.:?;$'']' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # Define um padrão de regex para encontrar emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # Símbolos e pictogramas diversos\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # Transporte e símbolos de mapa\n",
    "                               u\"\\U0001F700-\\U0001F77F\"  # Símbolos de alquimia, religião e zodíaco\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"  # Símbolos de traços diversos\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"  # Símbolos de escrita linear abugida\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Símbolos suplementares de escrita linear abugida\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"  # Símbolos de xadrez\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Símbolos de emojis adicionais\n",
    "                               u\"\\U0001F004-\\U0001F0CF\"  # Símbolos de cartas de baralho\n",
    "                               u\"\\U0001F170-\\U0001F251\"  # Símbolos de emojis de comemoração\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    # Substitui os emojis por uma string vazia\n",
    "    clean_text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    return clean_text\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Limpeza dos comentários\n",
    " A limpeza de dados é essencial para a criação do classificador, visto que ela retire todos caracteres que não interferem no sentido semântico de um comentário, evitando assim que eles sejam classificados por aspectos que não são o obejetivo e, consequentemente, aumentando a precisão dele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " total de palavras coletadas de comentários relevantes: 8098 \n",
      " total de palavras coletadas de comentários irrelevantes: 8034 \n",
      " total de palavras coletadas: 16132 \n"
     ]
    }
   ],
   "source": [
    "palavras_relevantes = []             #Lista com as palvras de feedbacks relevantes.\n",
    "palavras_irrelevantes = []         #Lista com as palvras de feedbacks irrelevantes.\n",
    "\n",
    "train_relevantes = train.loc[train.Target == 'Relevante', :]        #base de dados relevante\n",
    "train_irrelevantes = train.loc[train.Target == 'Irrelevante', :]        #base de dados irrelevantes\n",
    "\n",
    "for i in range(len(train_relevantes)):      #Limpando os emojis e potuação da base de dados relevante e colocando as palavras em uma lista.\n",
    "    palavras_relevantes += cleanup(remove_emojis(train_relevantes.iloc[i, 0].lower())).split()\n",
    "\n",
    "for i in range(len(train_irrelevantes)):    #Limpando os emojis e pontuação da base de dados irrelevante e colocando as palavras em uma lista.\n",
    "    palavras_irrelevantes += cleanup(remove_emojis(train_irrelevantes.iloc[i, 0].lower())).split()\n",
    "\n",
    "#Tirando númreros das listas de palavras.\n",
    "\n",
    "for i in range(len(palavras_relevantes)):\n",
    "    for caractere in palavras_relevantes[i]:\n",
    "        if caractere.isdigit():\n",
    "            palavras_relevantes[i] = ''\n",
    "    \n",
    "for i in range(len(palavras_irrelevantes)):\n",
    "    for caractere in palavras_irrelevantes[i]:\n",
    "        if caractere.isdigit():\n",
    "            palavras_irrelevantes[i] = ''\n",
    "\n",
    "#Criando lista com todas as palavras\n",
    "total_palavras = palavras_relevantes + palavras_irrelevantes\n",
    "\n",
    "print( f'\\n total de palavras coletadas de comentários relevantes: {len(palavras_relevantes)} '\n",
    "      f'\\n total de palavras coletadas de comentários irrelevantes: {len(palavras_irrelevantes)} '\n",
    "      f'\\n total de palavras coletadas: {len(total_palavras)} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza_relevantes (treino):\n",
    "    palavras_relevantes = []             #Lista com as palvras de feedbacks relevantes.\n",
    "\n",
    "    train_relevantes = train.loc[train.Target == 'Relevante', :]        #base de dados relevante\n",
    "\n",
    "    for i in range(len(train_relevantes)):      #Limpando os emojis e potuação da base de dados relevante e colocando as palavras em uma lista.\n",
    "        palavras_relevantes += cleanup(remove_emojis(train_relevantes.iloc[i, 0].lower())).split()\n",
    "\n",
    "    #Tirando númreros das listas de palavras.\n",
    "\n",
    "    for i in range(len(palavras_relevantes)):\n",
    "        for caractere in palavras_relevantes[i]:\n",
    "            if caractere.isdigit():\n",
    "                palavras_relevantes[i] = ''\n",
    "        \n",
    "    return palavras_relevantes\n",
    "\n",
    "def limpeza_irrelevante (treino):\n",
    "    palavras_irrelevantes = []         #Lista com as palvras de feedbacks irrelevantes.\n",
    "\n",
    "    train_irrelevantes = train.loc[train.Target == 'Irrelevante', :]        #base de dados irrelevantes\n",
    "\n",
    "    for i in range(len(train_irrelevantes)):    #Limpando os emojis e pontuação da base de dados irrelevante e colocando as palavras em uma lista.\n",
    "        palavras_irrelevantes += cleanup(remove_emojis(train_irrelevantes.iloc[i, 0].lower())).split()\n",
    "\n",
    "    #Tirando númreros das listas de palavras.\n",
    "\n",
    "    for i in range(len(palavras_irrelevantes)):\n",
    "        for caractere in palavras_irrelevantes[i]:\n",
    "            if caractere.isdigit():\n",
    "                palavras_irrelevantes[i] = ''\n",
    "\n",
    "    return palavras_irrelevantes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Criando pd.series para cada Target\n",
    "Aqui vamos transformar a lista de palavras em uma serie para poder utilizar algumas funcões que ajudam a tratar melhor os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando Série para palavras relevantes\n",
    "serie_relevantes = pd.Series(palavras_relevantes)\n",
    "\n",
    "#Criando Série para palavras não relevantes\n",
    "serie_irrelevantes = pd.Series(palavras_irrelevantes)\n",
    "\n",
    "#Criando série para todas as palavras:\n",
    "serie_total = pd.Series(total_palavras)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Gerando tabela de frequências para as Séries\n",
    " A tabela de frequêcia é essencial para o calculo, visto que ela gera a probabilidade de cada palavra aparecer, ou seja, ela gera a porcentagem que essa palavra apareceu em relação ao total de palavras. Essa porcentagem irá ser utilizada como uma variavel independente para calcular a chance de um comentário ser relevantes ou irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " total de palavras diferente coletadas de comentários relevantes: 1994\n",
      " total de palavras diferente coletadas de comentários irrelevantes: 2219\n",
      " total de palavras diferente coletadas: 3486\n"
     ]
    }
   ],
   "source": [
    "#Tabela de frequência absoluto de palavras relevantes\n",
    "tabela_relevante_absoluto = serie_relevantes.value_counts()\n",
    "#Tabela de frequência relativa de palavras relevantes\n",
    "tabela_relevante_frequencia = serie_relevantes.value_counts(True)\n",
    "\n",
    "\n",
    "#Tabela de frequência absoluta de palavras não relevantes\n",
    "tabela_irrelevante_absoluto = serie_irrelevantes.value_counts()\n",
    "#Tabela de frequência relativa de palavras não relevantes\n",
    "tabela_irrelevante_frequencia = serie_irrelevantes.value_counts(True)\n",
    "\n",
    "\n",
    "#Tabela de frequência absoluta de todas as palavras\n",
    "tabela_total_absoluto = serie_total.value_counts()\n",
    "#Tabela de frequência relativa de todas as palavras\n",
    "tabela_total_frequencia = serie_total.value_counts(True)\n",
    "\n",
    "\n",
    "print( f'\\n total de palavras diferente coletadas de comentários relevantes: {len(tabela_relevante_absoluto)}' \n",
    "      f'\\n total de palavras diferente coletadas de comentários irrelevantes: {len(tabela_irrelevante_absoluto)}'\n",
    "      f'\\n total de palavras diferente coletadas: {len(tabela_total_absoluto)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Suavilização de Laplace\n",
    " A suavilização de Laplace é utilizada para evitar que palavras que apareceram nos dados de testes, mas não nos de treinamento, acabem zerando a conta da probabilidade, que é feita pela multiplicação das variaveis independentes (no caso a probabilidade de cada palavra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_relevante (comentario):\n",
    "    if len(comentario) > 0:\n",
    "        palavras = comentario\n",
    "    P_i = 1\n",
    "    for i in palavras:\n",
    "        P_i *=  (tabela_relevante_absoluto[i] + 1) / (tabela_relevante_absoluto.sum() + len(tabela_total_absoluto))\n",
    "\n",
    "    return P_i\n",
    "\n",
    "def laplace_irrelevante (comentario):\n",
    "    if len(comentario) > 0:\n",
    "        palavras = comentario\n",
    "    P_i = 1\n",
    "    for i in palavras:\n",
    "        P_i *=  (tabela_irrelevante_absoluto[i] + 1) / (tabela_irrelevante_absoluto.sum() + len(tabela_total_absoluto))\n",
    "\n",
    "    return P_i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teoria\n",
    "\n",
    "Naive Bayes é um algoritmo de classificação probabilístico que utiliza o Teorema de Bayes para inferir a classe de uma amostra. Ele é frequentemente usado na área de Data Science para categorizar textos com base na frequência de palavras que aparecem nos mesmos. A grande vantagem do Naive Bayes é a sua simplicidade e a forma \"ingênua\" como ele trata as variáveis, assumindo que elas são independentes entre si.\n",
    "\n",
    "Para utilizar o algoritmo Naive Bayes na programação, é necessário seguir algumas etapas. Primeiro, são definidas algumas probabilidades como a probabilidade de um comentário em produtos da Amazon ser, ou relevante (como definimos anteriormente), ou irrelevante (como definido anteriormente também), bem como a probabilidade de um comentário ser classificado como um desses Targets, dada que foi classificada como uma delas. Em seguida, são calculadas essas probabilidades, utilizando técnicas como a suavização de Laplace para evitar casos em que uma palavra não esteja na base de dados.\n",
    "\n",
    "Para calcular a probabilidade de um comentário ser classificado como algum dos Targets, é necessário contar o número de palavras dos comentários classificados como esse Target e dividir pelo número total de palavras de todas as notícias.\n",
    "\n",
    "Por fim, para inferir a classe de uma amostra, é necessário calcular as probabilidades condicionais utilizando o Teorema de Bayes e escolher a classe com a maior probabilidade. É importante lembrar que o Naive Bayes assume que as variáveis são independentes entre si, o que pode levar a uma classificação incorreta em alguns casos. <strong>Segue abaixo um pouco do raciocínio matemático: </strong>\n",
    "\n",
    "##### Definindo algumas probabilidades:\n",
    "- $P(Comentário|Relevante)$: probabilidade de encontrar o comentário dado as palavras Relevantes;\n",
    "- $P(Comentário|Irrelevante)$: probabilidade de encontrar o comentário dado as palavras Irrelevantes;\n",
    "- $P(Relevante)$: probabilidade do comentário ser Relevante;\n",
    "- $P(Irrelevante)$: probabilidade do comentário ser Irrelevante;\n",
    "- $P(Comentário)$: probabilidade do comentário ocorrer.\n",
    "\n",
    "\n",
    "$$P(Relevante|Comentário) = \\frac{P(Comentário|Relevante) P(Relevante)}{P(Comentário)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Irrelevante|Comentário) = \\frac{P(Comentário|Irrelevante) P(Irrelevante)}{P(Comentário)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Primeiramente vamos calcular as seguintes probabilidades: $P(Relevante)$, $P(Irrelevante)$.\n",
    "\n",
    "\n",
    "- Número de palavras dos comentários relevantes: $Nr$\n",
    "- Número de palavras dos comentários irrelevantes: $Ni$\n",
    "- Número total de palavras: $Nt$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Relevante) = \\frac{Nr}{Nt}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Irrelevante) = \\frac{Ni}{Nt}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Feito isso, vamos calcular as seguinte probabilidades: $P(Comentário|Relevante)$ , $P(Comentário|Irrelevante)$.\n",
    "\n",
    "Como calcular essa probabiilidades? Será necessário dividir as palavras de um comentário, e calcular a frequência absoluta de vezes que essa palavra aparece no total de palavras em cada Target, e dessa maneira, dividir pelo valor total de palavras que estão no conjunto de palavras dos comentários. Após feito isso é necessário multiplicar o valor obtido para cada palavra e assim temos a probabilidade $P()$ para um determinado comentário.\n",
    "\n",
    "Caso a palavras não esteja na nossa base de dados, utilizaremos a suavização de Laplace para prevenir casos como esse.\n",
    "\n",
    "### Suavização de Laplace:\n",
    "Esse método é utilizado para evitar que a probabilidade resulte em 0.\n",
    "Vamos mostrar isso com ajuda da matemática:\n",
    "\n",
    "- Se queremos calcular a probabilidade do comentário ser relevante dado que o comentário, porém, uma das palavras contidas nesse comentário não está na nossa base de dados. Usaremos portanto a suavização de Laplace.\n",
    "\n",
    "$$P(Palavra|Relevante) = \\frac{0}{Nr}$$\n",
    "\n",
    "Para que isso não aconteça nós somaremos 1 no numerador e para manter o equilíbrio somaremos a quantidade total de possíveis palavras da nossa base de dados:\n",
    "\n",
    "- Número total de possíveis palavras da nossa base de dados: $Npp$\n",
    "\n",
    "\n",
    "$$P(Palavra|Relevante) = \\frac{0 + 1}{Nr + Npp}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Sendo assim, nós teremos uma fórmula geral descrita da forma:\n",
    "\n",
    "- Frequência absoluta da palavra na lista de comentários relevantes: $Far$\n",
    "- Frequência absoluta da palavra na lista de comentários irrelevantes: $Fai$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Palavra|Relevante) = \\frac{Far + 1}{Nr + Npp}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Palavra|Irrelevante) = \\frac{Fai + 1}{Ni + Npp}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Com as duas fórmulas gerais, agora será necesséerio calcular a probabilidade de cada palavra, dado cada um dos dois Targetes, e multiplicar esses valores para obter a probabilidade de um comentário ser classificado como um dos dois Targets.\n",
    "Assim teremos, $P(Comentário|Relevante)$ e $P(Comentário|Irrelevante)$, das seguintes fórmulas:\n",
    "\n",
    "$$P(Relevante|Comentário) = \\frac{P(Comentário|Relevante) P(Relevante)}{P(Comentário)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Irrelevante|Comentário) = \\frac{P(Comentário|Irrelevante) P(Irrelevante)}{P(Comentário)}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Como o denominador é o mesmo para as duas fórmulas, podemos simplificar e obter a seguinte fórmula:\n",
    "\n",
    "$$P(Relevante|Comentário) = P(Comentário|Relevante) P(Relevante)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Irrelevante|Comentário) = P(Comentário|Irrelevante) P(Irrelevante)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Agora, para inferir a classe de uma amostra, é necessário calcular as probabilidades condicionais utilizando o Teorema de Bayes e escolher a classe com a maior probabilidade. É importante lembrar que o Naive Bayes assume que as variáveis são independentes entre si, o que pode levar a uma classificação incorreta em alguns casos.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Criando um coluna no nosso dataframe de teste para guardar os resultados do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando coluna 'Classificador' na base de dados de teste\n",
    "test['Classificador'] = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Classificando os comentários do dataframe de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classificador'] = ''\n",
    "P_R = len(palavras_relevantes)/len(total_palavras)                                                                              # Probabilidade de ser relevante\n",
    "P_I = len(palavras_irrelevantes)/len(total_palavras)                                                                            # Probabilidade de ser irrelevante\n",
    "\n",
    "for i in range(len(test.Mensagem)):                                                                                             # Loop para percorrer todas as linhas da base de dados de teste\n",
    "    comentario = test.iloc[i,0]                                                                                                 # Comentário a ser classificado\n",
    "    comentario_limpo = cleanup(remove_emojis(comentario.lower())).split()                                                       # Comentário limpo\n",
    "    produto_prob_R = 1                                                                                                          # Variável que armazena o produto das probabilidades de ser relevante\n",
    "    produto_prob_I = 1                                                                                                          # Variável que armazena o produto das probabilidades de ser irrelevante\n",
    "    for palavra in comentario_limpo:                                                                                            # Loop para percorrer todas as palavras do comentário\n",
    "        \n",
    "        if palavra not in palavras_relevantes:                                                                                  # Se a palavra não estiver na lista de palavras relevantes, adiciona ela com frequência 0, necessária para a suavização de Laplace\n",
    "            tabela_relevante_absoluto[palavra] = 0                  \n",
    "        \n",
    "        if palavra not in palavras_irrelevantes:                                                                                # Se a palavra não estiver na lista de palavras irrelevantes, adiciona ela com frequência 0, necessária para a suavização de Laplace\n",
    "            tabela_irrelevante_absoluto[palavra] = 0\n",
    "            \n",
    "\n",
    "        produto_prob_R *= (tabela_relevante_absoluto[palavra] + 1)/(len(palavras_relevantes) + len(tabela_total_absoluto))      # Calculando o produto das probabilidades de ser relevante\n",
    "        produto_prob_I *= (tabela_irrelevante_absoluto[palavra] + 1)/(len(palavras_irrelevantes) + len(tabela_total_absoluto))  # Calculando o produto das probabilidades de ser irrelevante\n",
    "        \n",
    "\n",
    "    probabilidade_relevante = produto_prob_R * P_R                                                                              # Calculando a probabilidade de ser relevante\n",
    "    probabilidade_irrelevante = produto_prob_I * P_I                                                                            # Calculando a probabilidade de ser irrelevante\n",
    "\n",
    "    if probabilidade_relevante > probabilidade_irrelevante:                                                                     # Se a probabilidade de ser relevante for maior que a probabilidade de ser irrelevante, classifica como relevante\n",
    "        test.iloc[i,2] = 'Relevante'                                                                                            # Classifica como relevante\n",
    "    else:                                                                                                                       # Se a probabilidade de ser irrelevante for maior que a probabilidade de ser relevante, classifica como irrelevante\n",
    "        test.iloc[i,2] = 'Irrelevante'                                                                                          # Classifica como irrelevante\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Verificando a performance do nosso classificador\n",
    "\n",
    "Coluna 'Target' são as classificações feitas manualmente\n",
    "\n",
    "Coluna 'Classificação' são as classificações feitas pelo nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Não sou de desistir de livro, mas neste não te...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tao ruim quanto o primeiro. Fonte não justific...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sou fã do canal, estava na primeira sessão da ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Péssimo. O autor claramente tem um visão disto...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>lixo de um astrólogo limítrofe</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Achei ridículo! Eu realmente esperava uma hist...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>As afirmações do autor, que é historiador, não...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Livro meio fantasioso , quer dizer que quase n...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Seria o ideal... E bebê,  nenê? Que mulher se ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem       Target  \\\n",
       "0    Não sou de desistir de livro, mas neste não te...  Irrelevante   \n",
       "1    EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...    Relevante   \n",
       "2    Tao ruim quanto o primeiro. Fonte não justific...    Relevante   \n",
       "3    Sou fã do canal, estava na primeira sessão da ...  Irrelevante   \n",
       "4    Péssimo. O autor claramente tem um visão disto...  Irrelevante   \n",
       "..                                                 ...          ...   \n",
       "195                     lixo de um astrólogo limítrofe  Irrelevante   \n",
       "196  Achei ridículo! Eu realmente esperava uma hist...  Irrelevante   \n",
       "197  As afirmações do autor, que é historiador, não...  Irrelevante   \n",
       "198  Livro meio fantasioso , quer dizer que quase n...  Irrelevante   \n",
       "199  Seria o ideal... E bebê,  nenê? Que mulher se ...  Irrelevante   \n",
       "\n",
       "    Classificador  \n",
       "0     Irrelevante  \n",
       "1       Relevante  \n",
       "2       Relevante  \n",
       "3     Irrelevante  \n",
       "4     Irrelevante  \n",
       "..            ...  \n",
       "195   Irrelevante  \n",
       "196   Irrelevante  \n",
       "197   Irrelevante  \n",
       "198   Irrelevante  \n",
       "199   Irrelevante  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>97.44</td>\n",
       "      <td>22.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>2.56</td>\n",
       "      <td>77.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador  Irrelevante  Relevante\n",
       "Target                               \n",
       "Irrelevante          97.44      22.73\n",
       "Relevante             2.56      77.27"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Target, test.Classificador, normalize='columns').round(4)*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentagem do comentário ser irrelevantes dado que foi classificado como irrelevante (verdadeiros negativos): 97.44%\n",
    "\n",
    "Porcentagem do comentário ser relevantes dado que foi classificado como irrelevante (falso negativo): 2.56%\n",
    "\n",
    "Porcentagem do comentário ser relevante dado que foi classificado como relevante (Verdadeiros positivos): 77.27% \n",
    "\n",
    "Porcentagem do comentário ser irrelevantes dado que foi classificado como relevante (falsos positivos): 22.73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificador</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>76.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificador  Irrelevante  Relevante\n",
       "Target                               \n",
       "Irrelevante           76.0        5.0\n",
       "Relevante              2.0       17.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do nosso classificador é de 93.0%\n"
     ]
    }
   ],
   "source": [
    "#Acurácia do nosso classificador:\n",
    "tabela_de_acertos = pd.crosstab(test.Target, test.Classificador, normalize='all').round(4)*100\n",
    "acuracia = tabela_de_acertos.iloc[0,0] + tabela_de_acertos.iloc[1,1]\n",
    "display(tabela_de_acertos)\n",
    "print('A acurácia do nosso classificador é de {}%'.format(acuracia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após a análise do nosso classificador, podemos concluir que:\n",
    "\n",
    "    Porcentagem do comentário ser irrelevantes dado que foi classificado como irrelevante (verdadeiros negativos): 97.44%\n",
    "\n",
    "    Porcentagem do comentário ser relevantes dado que foi classificado como irrelevante (falso negativo): 2.56%\n",
    "\n",
    "    Porcentagem do comentário ser relevante dado que foi classificado como relevante (Verdadeiros positivos): 77.27% \n",
    "\n",
    "    Porcentagem do comentário ser irrelevantes dado que foi classificado como relevante (falsos positivos): 22.73%\n",
    "\n",
    "    O classificador teve uma acurácia de 93,0% na classificação dos comentários. \n",
    "\n",
    "    Com base nessa porcentagens podemos concluir que o classficador gerou bons resultados como uma primeira hipótese, porém, ainda há espaço para melhorias, já que sua acurácia não é de 100%.\n",
    "\n",
    "    Em relação a classificação dos testes, não é preciso se preocupar muito com a classificação de comentários irrelevantes, visto que a porcentagem de verdadeiros negativos é muito alta (97%), e muito baixa de falso negativos(3%), dessa maneira a maior parte dos comentários irrelevantes poderão ser descartados com confiança, o que poderá poupar muito tempo para a empresa, pois não irá precisar ler mensagens que não agregam em nada. Entretanto, a porcentagem de verdadeiros positivos (77%) pode ser um pouco preocupante, pois existe uma chance de (23%) do cometário ser falso positivo, algo que pode acabar atrasando a leitura dos comentários, pois existirão textos irrelevantes no bloco dos relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analise qualitativa dos resultados:\n",
    "\n",
    "    Ao analisar os resultados conclui-se que a maioria dos comentários recebidos são irrelevantes (76%) e foram classificados dessa maneira, ou seja, são críticas sobre os livros e o conteúdo deles e, portanto, não agregam nada ao desenvolvimento das empresas, no caso a Amazon, editora e distribuidora, sendo assim, devem ser ignorados. Porém 17% dos cometários são classificados como Relevantes, e devem ser analisados por essas empresas para entender quais aspectos delas estão sendo elogiados e quais estão sendo problematizados, por exemplo, para a Amazon um aspecto que foi muito questionado foi o alto preço dos livros, já para a editora o material para da capa e das folhas do livros, enquanto para a distribuidora foi o estado que o livro chegou para o destinatário. Sendo assim, essas empresas devem analisar esses cometários para criar um plano que visa melhorar esses serviços. \n",
    "\n",
    "    Em relação aos comentários que foram classificados de maneira incorreta (7% ao todo), por serem uma porcentagem pequena de erros eles não iram afetar muito a analise, visto que 5% são comentários irrelevantes que foram classificados como relevantes, o que não irá atrapalhar o desenvolvimento da empresa, somente demandar um pouco mais de tempo para ler todas mensagens. Entretanto os 2% restantes que são os falsos negativos, são preocupantes, pois são conteúdos que irão agragar para o desenvolvimento da empresa, mas nunca serão analisados já que foram classificados como irrelevantes. Entretanto esse porcentual é muito baixo, e com mais investimento no projeto ele pode diminuir ainda mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barreiras a serem superandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como ocorre o tratamento de mensagens com dupla negação e sarcasmo?\n",
    "    Os comentários que possuem dupla negação ou sarcasmo são tratadas assim como todos os outros, por ser uma classificador que avalia o comentário baseado na frequência em que as palavras aparecem ele não compreende o sentido semântico das frases. Dessa forma, o caso de mensagens que dizem algo, mas possuem o intuito de se referirem ao sentido oposto, elas acabam possuindo mais chance de serem classificados inadequadamente, pois irão possuir palavras chaves que são de um grupo target oposto ao dela."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por quê não usar o próprio classificador para gerar mais amostras de treinamento?\n",
    "\n",
    "    Não podemos usar o próprio classificador para gerar mais amostras de treinamento, pois o classificador não ia criar palavras novas, portanto ia criar mais frases com as mesmas palavras, somente diferentes combinações, e isso não iria ajudar a melhorar o classificador, pois não iria criar frases genéricas. \n",
    "\n",
    "    Ademais, as novas amostras criadas pelo classificador podem ser mensagens que não possuem nenhum sentido semântico, algo que não irá agregar vantegens para ele, pois serão comentários que na realidade não poderão ser classificados em nenhuma classe, ou poderão ser classificadas nas duas.\n",
    "\n",
    "    Por exemplo se o classificador gerar a seguinte frase: \"não Amazon leitura rasgado\", essa frase possui palavras importantes para ambas as classes porém juntas e nessa ordem não fazem nenhum sentido, somente iria bagunçar as probabilidades do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximos passos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importancia da empresa continuar investindo no nosso projeto:\n",
    "    O projeto teve um alto nível de acurácia sem utilizar muitas melhorias, dessa forma o financiamento no projeto é essencial para continuar melhorando nosso classificador, é notavel que não se trata de um classificador muito sofisticado, porém existe algumas melhorais que podemos fazer com mais investimento, por exemplo incrementar a seleção e limpeza de dados, em seguida encontrar novos meios para relacionar as diversas palavras e, por último, pesquisar a melhor maneira de tratar comentários sarcasticos ou de dupla negação."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferentes cenários para o classificador Naive-Bayes\n",
    "\n",
    "1. O classificador Naive-Bayes pode ser utilizado para classficar qual time uma pessoa torçe com base em comentários feitos em redes sociais a respeito de futebool, certas palavras chaves podem indicar qual time a pessoa torçe, como por exemplo, \"Flamengo\" e \"Mengão\" indicam que a pessoa torçe para o Flamengo, e assim por diante.\n",
    "\n",
    "2. O classificador Naive-Bayes, também pode ser utilizado para classificar artigos públicados, como por exemplo, artigos de opinião, artigos de notícias, artigos de entretenimento, artigos de esportes, etc. Para isso, basta criar uma base de dados com palavras chaves que indicam cada tipo de artigo, e assim, o classificador poderá classificar os artigos de acordo com as palavras chaves contidas neles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Melhorias reais com indicações concretas de como implementar\n",
    "\n",
    "1. Uma das inúmeras melhorias que podem ser aplicadas ao nosso classificador é a utilização de uma base de dados maior, com mais comentários, pois assim, o classificador terá mais palavras para trabalhar, e assim, terá uma maior acurácia.\n",
    "\n",
    "2. Outra melhoria que pode ser aplicada é uma limpeza mais abrangente de palavras e elementos irrelevantes para os comentários, assim teriamos uma base de dados mais limpa, com mais palvras-chaves e menos ruídos. Por exemplo, podem ser utilizados, lemmatization, que é a redução de palavras flexionadas à sua forma base, ou seja, ao lema. Por exemplo, a palavra \"correria\" seria reduzida para \"correr\", e assim por diante. Outra técnica que pode ser utilizada é a remoção de stopwords, que são palavras que não possuem significado, como por exemplo, \"a\", \"o\", \"de\", \"para\", etc. Essas técnicas foram apresentadas na rúbrica e mais aprofundada no site Geeks for Geeks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando base de dados com todos os comentários\n",
    "dados_totais = pd.concat([train, test], ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fique atento na compra. Ainda está com problem...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Talvez a tradução antiga tivesse um pouco mais...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sinceramente, também estou tentando entender c...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Escolhi o livro por acreditar no tema e indica...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recebi o produto avariado, no mesmo dia reclam...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>lixo de um astrólogo limítrofe</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Achei ridículo! Eu realmente esperava uma hist...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>As afirmações do autor, que é historiador, não...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Livro meio fantasioso , quer dizer que quase n...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Seria o ideal... E bebê,  nenê? Que mulher se ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem       Target\n",
       "0    Fique atento na compra. Ainda está com problem...    Relevante\n",
       "1    Talvez a tradução antiga tivesse um pouco mais...    Relevante\n",
       "2    Sinceramente, também estou tentando entender c...    Relevante\n",
       "3    Escolhi o livro por acreditar no tema e indica...  Irrelevante\n",
       "4    Recebi o produto avariado, no mesmo dia reclam...    Relevante\n",
       "..                                                 ...          ...\n",
       "495                     lixo de um astrólogo limítrofe  Irrelevante\n",
       "496  Achei ridículo! Eu realmente esperava uma hist...  Irrelevante\n",
       "497  As afirmações do autor, que é historiador, não...  Irrelevante\n",
       "498  Livro meio fantasioso , quer dizer que quase n...  Irrelevante\n",
       "499  Seria o ideal... E bebê,  nenê? Que mulher se ...  Irrelevante\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apagando a coluna 'Classificador' da base de dados com todos os comentários para classificar novamente usando a função train_test_split\n",
    "dados_totais.drop('Classificador', axis= 1 , inplace = True)\n",
    "dados_totais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2) (200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Verificando e testando o funcionamento da função train_test_slipt\n",
    "dados_treino_split, dados_teste_split = train_test_split(dados_totais, test_size=0.4, random_state=100)\n",
    "print(dados_treino_split.shape, dados_teste_split.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualidade do Classificador a partir de novas separações dos comentários entre treinamento e teste\n",
    "acuracia_100 = []\n",
    "\n",
    "for n in range(0,100):\n",
    "    # Separando todos comentários em dois df, um de teste e um de treino\n",
    "    dados_treino_100, dados_teste_100 = train_test_split(dados_totais, test_size=0.4, random_state= n)\n",
    "\n",
    "    #limpeza dos dados, utilizando as funções criadas no 2 (limpeza dos comentários)\n",
    "    palavras_relevantes_100 = limpeza_relevantes(dados_treino_100)\n",
    "    palavras_irrelevantes_100 = limpeza_irrelevante(dados_treino_100)\n",
    "\n",
    "    #Criando lista com todas as palavras\n",
    "    total_palavras_100 = palavras_relevantes_100 + palavras_irrelevantes_100\n",
    "\n",
    "    #Criando Série para palavras relevantes\n",
    "    serie_relevantes_100 = pd.Series(palavras_relevantes_100)\n",
    "\n",
    "    #Criando Série para palavras não relevantes\n",
    "    serie_irrelevantes_100 = pd.Series(palavras_irrelevantes_100)\n",
    "\n",
    "    #Criando série para todas as palavras:\n",
    "    serie_total_100 = pd.Series(total_palavras_100)\n",
    "\n",
    "\n",
    "    #Tabela de frequência absoluto de palavras relevantes\n",
    "    tabela_relevante_absoluto_100 = serie_relevantes_100.value_counts()\n",
    "    #Tabela de frequência relativa de palavras relevantes\n",
    "    tabela_relevante_frequencia_100 = serie_relevantes_100.value_counts(True)\n",
    "\n",
    "    #Tabela de frequência absoluta de palavras não relevantes\n",
    "    tabela_irrelevante_absoluto_100 = serie_irrelevantes_100.value_counts()\n",
    "    #Tabela de frequência relativa de palavras não relevantes\n",
    "    tabela_irrelevante_frequencia_100 = serie_irrelevantes_100.value_counts(True)\n",
    "\n",
    "    #Tabela de frequência absoluta de todas as palavras\n",
    "    tabela_total_absoluto_100 = serie_total_100.value_counts()\n",
    "    #Tabela de frequência relativa de todas as palavras\n",
    "    tabela_total_frequencia_100 = serie_total_100.value_counts(True)\n",
    "\n",
    "\n",
    "    dados_teste_100['Classificador'] = ''\n",
    "    P_R = len(palavras_relevantes_100)/len(total_palavras_100)    # Probabilidade de ser relevante\n",
    "    P_I = len(palavras_irrelevantes_100)/len(total_palavras_100)    # Probabilidade de ser irrelevante\n",
    "\n",
    "    for i in range(len(dados_teste_100.Mensagem)):         # Loop para percorrer todas as linhas da base de dados de teste\n",
    "        comentario = dados_teste_100.iloc[i,0]        # Comentário a ser classificado\n",
    "        comentario_limpo = cleanup(remove_emojis(comentario.lower())).split()                # Comentário limpo\n",
    "        produto_prob_R = 1                    # Variável que armazena o produto das probabilidades de ser relevante\n",
    "        produto_prob_I = 1                        # Variável que armazena o produto das probabilidades de ser irrelevante\n",
    "        for palavra in comentario_limpo:                # Loop para percorrer todas as palavras do comentário\n",
    "            \n",
    "            if palavra not in palavras_relevantes_100:      # Se a palavra não estiver na lista de palavras relevantes, adiciona ela com frequência 0, necessária para a suavização de Laplace\n",
    "                tabela_relevante_absoluto_100[palavra] = 0                  \n",
    "            \n",
    "            if palavra not in palavras_irrelevantes_100:     # Se a palavra não estiver na lista de palavras irrelevantes, adiciona ela com frequência 0, necessária para a suavização de Laplace\n",
    "                tabela_irrelevante_absoluto_100[palavra] = 0\n",
    "                \n",
    "\n",
    "            produto_prob_R *= (tabela_relevante_absoluto_100[palavra] + 1)/(len(palavras_relevantes_100) + len(tabela_total_absoluto_100))      # Calculando o produto das probabilidades de ser relevante\n",
    "            produto_prob_I *= (tabela_irrelevante_absoluto_100[palavra] + 1)/(len(palavras_irrelevantes_100) + len(tabela_total_absoluto_100))  # Calculando o produto das probabilidades de ser irrelevante\n",
    "            \n",
    "\n",
    "        probabilidade_relevante = produto_prob_R * P_R                                                                              # Calculando a probabilidade de ser relevante\n",
    "        probabilidade_irrelevante = produto_prob_I * P_I                                                                            # Calculando a probabilidade de ser irrelevante\n",
    "\n",
    "        if probabilidade_relevante > probabilidade_irrelevante:                                                                     # Se a probabilidade de ser relevante for maior que a probabilidade de ser irrelevante, classifica como relevante\n",
    "            dados_teste_100.iloc[i, 2] = 'Relevante'                                                                                            # Classifica como relevante\n",
    "        else:                                                                                                                       # Se a probabilidade de ser irrelevante for maior que a probabilidade de ser relevante, classifica como irrelevante\n",
    "            dados_teste_100.iloc[i, 2] = 'Irrelevante'   \n",
    "              \n",
    "    #calculando a acurácia\n",
    "    tabela_de_acertos_100 = pd.crosstab(dados_teste_100.Target, dados_teste_100.Classificador, normalize='all').round(4)*100\n",
    "    acertos = tabela_de_acertos_100.iloc[0,0] + tabela_de_acertos_100.iloc[1,1]\n",
    "    # adicionando a precisão a lista de todas elas\n",
    "    acuracia_100.append(acertos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>93.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>91.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>93.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>94.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>97.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "count  100.0000\n",
       "mean    93.8150\n",
       "std      1.2606\n",
       "min     91.0000\n",
       "25%     93.0000\n",
       "50%     94.0000\n",
       "75%     94.5000\n",
       "max     97.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95.0, 93.5, 95.5, 92.5, 93.5, 94.0, 94.0, 94.5, 94.5, 94.0, 95.0, 94.0, 92.0, 94.5, 93.0, 93.5, 94.0, 91.0, 95.0, 93.0, 95.0, 93.5, 92.0, 91.5, 92.5, 91.5, 93.5, 94.0, 95.5, 94.0, 96.0, 93.5, 94.0, 92.0, 93.0, 94.0, 91.5, 91.5, 94.5, 96.5, 94.5, 92.5, 94.0, 94.0, 92.5, 91.5, 94.0, 95.0, 93.0, 93.0, 94.5, 94.0, 94.0, 92.5, 94.5, 94.5, 96.0, 96.0, 95.5, 94.5, 95.0, 93.5, 92.0, 94.5, 96.0, 96.0, 94.5, 95.0, 92.0, 93.5, 94.0, 93.0, 93.5, 95.5, 92.5, 94.5, 94.5, 95.0, 93.0, 95.5, 93.0, 91.5, 94.0, 94.0, 93.0, 93.0, 93.0, 94.0, 94.5, 93.5, 92.5, 93.0, 95.0, 92.5, 94.5, 92.5, 94.0, 97.0, 94.5, 94.0]\n"
     ]
    }
   ],
   "source": [
    "# Obtendo detalhes sobre os dados de precisão para poder realizar uma analise na conclusão\n",
    "acuracia_series = pd.Series(acuracia_100)\n",
    "display(acuracia_series.describe().to_frame().round(4))\n",
    "print(acuracia_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAIhCAYAAAAPRs1dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9AUlEQVR4nO3de1hVVf7H8c8R5KIGXlDARCBMctTUsBQduxqm5i2bUMtbMuXPmsbspvnkbWqwyWu/8lZ4KzMqzWnUMqa0LC1LwZrR1DERRQylBFMDgfX7o8fzmxOgXI6cpbxfz7Ofh7PO2mt/9wr109r77OMwxhgBAADAo2p5ugAAAAAQygAAAKxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyABXyzDPPqHHjxtq3b5+nS0EVZWVlKSQkRH/+8589XQoAEcqAy9KLL74oh8OhNm3auHXcDz74QHPmzNG6det09dVXu7y3adMmORwObdq0ydk2ZcoUORwOt9ZQWSNGjFBERISny7BGYWGh4uPjdeONN2r27NmVGoM5BdyLUAZchhYvXixJ+ve//60vv/zSLWMeOnRII0aMUHJysm644YZy7ZOQkKCtW7e65fhwr6efflpeXl567bXXVKtW5f4peOaZZ/Tuu++6uTKg5vL2dAEA3Ovrr7/Wzp071bt3b61bt05JSUnq1KlTlccNCwvT0aNHK7RPs2bN1KxZsyofG1VjjNEvv/wif39/Z9vf/va3Ko8bFRVV5TEA/D9WyoDLTFJSkiRp+vTp6tKli958802dPn3apU96erocDodmzJihWbNmKTIyUvXq1VNsbKy++OILl75ff/21Bg0apIiICPn7+ysiIkKDBw/WwYMHL1hLaZcvP/74Y918881q1KiR/P391bx5cw0cONClxoKCAj377LO65ppr5Ovrq8aNG2vkyJE6duxYueZg6dKlio6Olq+vr1q1aqXly5eX2m/q1Knq1KmTGjZsqICAAF133XVKSkqSMabCNZcmOTlZcXFxCg0Nlb+/v1q1aqXx48fr1KlTJfp++eWX6tOnjxo1aiQ/Pz9FRUVp7NixzvfLulRY2hw7HA49/PDDWrBggVq1aiVfX18tW7asQucsSW+88YZiY2NVr1491atXT+3bt3f+fpVV08svv6wbb7xRTZo0Ud26ddW2bVv97W9/09mzZ136paam6s4771STJk3k6+urpk2bqnfv3jp8+PB55xS4nLFSBlxGzpw5o5UrV+r6669XmzZtdP/99yshIUFvv/22hg8fXqL/yy+/rGuuuUZz5syR9OvlqF69eunAgQMKDAyUJH3//feKiorSH/7wBzVu3FhZWVmaN2+err/+eu3atUtBQUHlri89PV29e/dWt27dtHjxYtWvX1+ZmZn64IMPVFBQoDp16qi4uFj9+vXT5s2b9eSTT6pLly46ePCgJk+erJtvvllff/21y4rPby1dulQjR45Uv379NHPmTOXm5mrKlCnKz88vcZkuPT1dDz74oJo3by5J+uKLL/SnP/1JmZmZmjRpUrlrLsu+ffvUq1cvjR07VnXr1tV3332n559/Xtu2bdPHH3/s7Ldhwwb16dNHrVq10qxZs9S8eXOlp6frww8/LPfc/taaNWu0efNmTZo0SSEhIWrSpIkkaf/+/UpISFB4eLhq1apV6jlL0qRJk/SXv/xFd911lx577DEFBgbqX//61wXD+P79+zVkyBBFRkbKx8dHO3fu1HPPPafvvvvOeVn91KlTuv322xUZGamXX35ZwcHBOnr0qDZu3KiTJ09W+pyBS54BcNlYvny5kWQWLFhgjDHm5MmTpl69eqZbt24u/Q4cOGAkmbZt25rCwkJn+7Zt24wks3LlyvMe58yZM6ZOnTpm7ty5zraNGzcaSWbjxo3OtsmTJ5v//mvmnXfeMZJMWlpamWOvXLnSSDKrVq1yaf/qq6+MJDNv3rwy9y0qKjJNmzY11113nSkuLna2p6enm9q1a5vw8PDz7nv27Fkzbdo006hRI+f+5am5PIqLi83Zs2fNJ598YiSZnTt3Ot+LiooyUVFR5syZM2XuP3z48FLr/+0cG2OMJBMYGGh+/PHHctX223P+/vvvjZeXl7n33nvPu19ZNZ1zbk6XL19uvLy8nPV8/fXXRpJZs2ZNueoDagouXwKXkaSkJPn7+2vQoEGSpHr16ukPf/iDNm/eXOojLHr37i0vLy/n62uvvVaSXFZDzpw5o6lTp6pdu3aqX7++/P39Vb9+fZ0+fVq7d++uUH3t27eXj4+PHnjgAS1btkzff/99iT5r165V/fr11adPHxUWFjq39u3bKyQkxOXTnb+1Z88eHTlyREOGDHG5pBceHq4uXbqU6P/xxx+re/fuCgwMlJeXl2rXrq1JkyYpJydH2dnZ5a65LN9//72GDBmikJAQ5/g33XSTJDnnbu/evdq/f79GjRolPz+/co99IbfeeqsaNGhQov3zzz9Xv379dOWVV6pOnTry8/PTtGnTXM45JSVFRUVFeuihhyp83NTUVPXt21eNGjVynvOwYcNUVFSkvXv3SpJatGihBg0a6KmnntKCBQu0a9euqp0scJkglAGXif/85z/69NNP1bt3bxljdOLECZ04cUJ33323pP//ROZ/a9SokctrX19fSb8GsXPuu+8+zZgxQ6NGjdIHH3ygHTt2KC0tTU2aNHHpVx5RUVH65z//qSZNmuihhx5SVFSUoqKiNHfuXGefH374QSdOnJCPj49q167tsh09elTHjx8vc/ycnBxJUkhISIn3ftu2bds2xcXFSZJeeeUVff755/rqq680ceJElzkoT82l+fnnn9WtWzd9+eWXevbZZ7Vp0yZ99dVXWr16tcv45+6Tc/cHIkJDQ0u0bd++XbfccovOnj2rRYsW6YsvvlBaWprzsmVVa8rIyFC3bt2UmZmpuXPnavPmzfrqq6/08ssvu4wfGBioTz75RO3bt9fTTz+t1q1bq2nTppo8eXKJe8+AmoR7yoDLxOLFi2WM0TvvvKN33nmnxPvLli3Ts88+67IydiG5ubl69913NXXqVD3yyCPO9l9++eW84eh8unXrpm7duqmoqEhff/21/vd//1djx45VcHCwBg0apKCgIDVq1EgffPBBqftfccUVZY59LmSW9inR37a9+eabql27ttauXeuyQrVmzZoK11yajz/+WEeOHNGmTZucq2OSdOLECZd+jRs3lqQL3uDu5+en/Pz8Eu1l/Xco7flwb7zxhry9vbVmzRr5+Pg4238brv+7prCwsPPW9d/WrFmjU6dOafXq1QoPD3e2p6Wllejbtm1bvfnmmzLG6JtvvtHSpUs1bdo0+fv7a/z48eU+JnA5YaUMuAwUFRVp2bJlioqK0saNG0tsjz32mLKysvT+++9XaFyHwyFjTIkgt2jRIhUXF1epZi8vL3Xq1Mm5irJjxw5J0p133qmcnBwVFRWpY8eOJbbo6Ogyx4yOjlZoaKhWrlzp8mnCgwcPasuWLSXOzdvb2+Xczpw5o9dee63CNZfmXCg6t/p4zsKFC11et2zZUlFRUVq8eHGpoeuciIgIZWdn64cffnC2FRQUaMOGDWXu81vGGNWqVcslsJ0+fbrEOcfFxcnLy0vz588v99hS6edsjNErr7xy3n3atWun2bNnq379+uedU+Byx0oZcBl4//33deTIET3//PO6+eabS7zfpk0bvfTSS0pKStKdd95Z7nEDAgLUrVs3zZgxQ40bN1ZkZKQ2btyoJUuWqH79+hWuc8GCBfr444/Vu3dvNW/eXL/88ovzsmr37t0lSYMGDdKKFSvUq1cv/fnPf9YNN9yg2rVr6/Dhw9q4caP69eunAQMGlDp+rVq19Je//EUJCQkaMGCA/vjHP+rEiROaMmVKicuXvXv31qxZszRkyBA98MADysnJ0YwZM0qEqPLUXJouXbqoQYMGGj16tCZPnqzatWtrxYoV2rlzZ4m+L7/8svr06aPOnTvr0UcfVfPmzZWRkaENGzZoxYoVkqT4+HhNmjRJgwYN0hNPPKFffvlFL774ooqKiso5+7+e8+zZszVo0CCNHj1aOTk5euGFF0p8mjUiIkJPP/20/vKXv+jMmTMaPHiwAgMDtWvXLh0/flxTp04tdfzbb79dPj4+Gjx4sJ588kn98ssvmj9/vn766SeXfmvXrtW8efPUv39/XXXVVTLGaPXq1Tpx4oRuv/32cp8PcNnx3GcMALhL//79jY+Pj8nOzi6zz6BBg4y3t7c5evSo89OXL7zwQol+kszkyZOdrw8fPmwGDhxoGjRoYK644gpzxx13mH/9618mPDzcDB8+3NmvPJ++3Lp1qxkwYIAJDw83vr6+plGjRuamm24y7733nksNZ8+eNTNmzDDt2rUzfn5+pl69euaaa64xDz74oNm3b98F5+PVV181V199tfHx8TEtW7Y0ixcvLvWTgosXLzbR0dHG19fXXHXVVSYxMdEkJSUZSebAgQMVqrk0W7ZsMbGxsaZOnTqmcePGJiEhwezYscNIMkuWLHHpu3XrVtOzZ08TGBhofH19TVRUlHn00Udd+qxfv960b9/e+Pv7m6uuusq89NJLZX768qGHHiq1pvKc8znLly83119/vfO/QYcOHVzqLm1O//GPfzj/u1155ZXmiSeeMO+//77L78Z3331nBg8ebKKiooy/v78JDAw0N9xwg1m6dOkF5xS4nDmMKeWJgQAAAKhW3FMGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAVq3MNji4uLdeTIEV1xxRWlfg0JAACAOxljdPLkSTVt2lS1apW9HlbjQtmRI0cq9F1uAAAA7nDo0CE1a9aszPdrXCg792XGhw4dUkBAgIerAQAAl7u8vDyFhYU5M0hZalwoO3fJMiAggFAGAACqzYVum+JGfwAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALCAx0PZvHnzFBkZKT8/P8XExGjz5s3n7Z+fn6+JEycqPDxcvr6+ioqK0uLFi6upWgAAgIvD25MHT05O1tixYzVv3jx17dpVCxcuVM+ePbVr1y41b9681H3uuece/fDDD0pKSlKLFi2UnZ2twsLCaq4cAADAvRzGGOOpg3fq1EnXXXed5s+f72xr1aqV+vfvr8TExBL9P/jgAw0aNEjff/+9GjZsWKlj5uXlKTAwULm5uQoICKh07QAAAOVR3uzhscuXBQUF2r59u+Li4lza4+LitGXLllL3ee+999SxY0f97W9/05VXXqmWLVvq8ccf15kzZ8o8Tn5+vvLy8lw2AAAA23js8uXx48dVVFSk4OBgl/bg4GAdPXq01H2+//57ffbZZ/Lz89O7776r48ePa8yYMfrxxx/LvK8sMTFRU6dOdXv9AGqmiPHrPF1ClaVP7+3pEgCUwuM3+jscDpfXxpgSbecUFxfL4XBoxYoVuuGGG9SrVy/NmjVLS5cuLXO1bMKECcrNzXVuhw4dcvs5AAAAVJXHVsqCgoLk5eVVYlUsOzu7xOrZOaGhobryyisVGBjobGvVqpWMMTp8+LCuvvrqEvv4+vrK19fXvcUDAAC4mcdWynx8fBQTE6OUlBSX9pSUFHXp0qXUfbp27aojR47o559/drbt3btXtWrVUrNmzS5qvQAAABeTRy9fjhs3Tq+++qoWL16s3bt369FHH1VGRoZGjx4t6ddLj8OGDXP2HzJkiBo1aqSRI0dq165d+vTTT/XEE0/o/vvvl7+/v6dOAwAAoMo8+pyy+Ph45eTkaNq0acrKylKbNm20fv16hYeHS5KysrKUkZHh7F+vXj2lpKToT3/6kzp27KhGjRrpnnvu0bPPPuupUwAAAHALjz6nzBN4ThmAquDTlwAqyvrnlAEAAOD/EcoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAs4PFQNm/ePEVGRsrPz08xMTHavHlzmX03bdokh8NRYvvuu++qsWIAAAD382goS05O1tixYzVx4kSlpqaqW7du6tmzpzIyMs673549e5SVleXcrr766mqqGAAA4OLwaCibNWuWRo0apYSEBLVq1Upz5sxRWFiY5s+ff979mjRpopCQEOfm5eVVTRUDAABcHB4LZQUFBdq+fbvi4uJc2uPi4rRly5bz7tuhQweFhobqtttu08aNG8/bNz8/X3l5eS4bAACAbTwWyo4fP66ioiIFBwe7tAcHB+vo0aOl7hMaGqpFixZp1apVWr16taKjo3Xbbbfp008/LfM4iYmJCgwMdG5hYWFuPQ8AAAB38PZ0AQ6Hw+W1MaZE2znR0dGKjo52vo6NjdWhQ4c0Y8YM3XjjjaXuM2HCBI0bN875Oi8vj2AGAACs47GVsqCgIHl5eZVYFcvOzi6xenY+nTt31r59+8p839fXVwEBAS4bAACAbTwWynx8fBQTE6OUlBSX9pSUFHXp0qXc46Smpio0NNTd5QEAAFQrj16+HDdunIYOHaqOHTsqNjZWixYtUkZGhkaPHi3p10uPmZmZWr58uSRpzpw5ioiIUOvWrVVQUKDXX39dq1at0qpVqzx5GgAAAFXm0VAWHx+vnJwcTZs2TVlZWWrTpo3Wr1+v8PBwSVJWVpbLM8sKCgr0+OOPKzMzU/7+/mrdurXWrVunXr16eeoUAAAA3MJhjDGeLqI65eXlKTAwULm5udxfBqDCIsav83QJVZY+vbenSwBqlPJmD49/zRIAAAAIZQAAAFYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFjA46Fs3rx5ioyMlJ+fn2JiYrR58+Zy7ff555/L29tb7du3v7gFAgAAVAOPhrLk5GSNHTtWEydOVGpqqrp166aePXsqIyPjvPvl5uZq2LBhuu2226qpUgAAgIvLo6Fs1qxZGjVqlBISEtSqVSvNmTNHYWFhmj9//nn3e/DBBzVkyBDFxsZe8Bj5+fnKy8tz2QAAAGzjsVBWUFCg7du3Ky4uzqU9Li5OW7ZsKXO/JUuWaP/+/Zo8eXK5jpOYmKjAwEDnFhYWVqW6AQAALgaPhbLjx4+rqKhIwcHBLu3BwcE6evRoqfvs27dP48eP14oVK+Tt7V2u40yYMEG5ubnO7dChQ1WuHQAAwN3Kl2wuIofD4fLaGFOiTZKKioo0ZMgQTZ06VS1btiz3+L6+vvL19a1ynQAAABeTx0JZUFCQvLy8SqyKZWdnl1g9k6STJ0/q66+/Vmpqqh5++GFJUnFxsYwx8vb21ocffqhbb721WmoHAABwN49dvvTx8VFMTIxSUlJc2lNSUtSlS5cS/QMCAvTtt98qLS3NuY0ePVrR0dFKS0tTp06dqqt0AAAAt/Po5ctx48Zp6NCh6tixo2JjY7Vo0SJlZGRo9OjRkn69HywzM1PLly9XrVq11KZNG5f9mzRpIj8/vxLtAAAAlxqPhrL4+Hjl5ORo2rRpysrKUps2bbR+/XqFh4dLkrKysi74zDIAAIDLgcMYYzxdRHXKy8tTYGCgcnNzFRAQ4OlyAFxiIsav83QJVZY+vbenSwBqlPJmD49/zRIAAAAIZQAAAFYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABaoUygoKCrRnzx4VFha6qx4AAIAaqVKh7PTp0xo1apTq1Kmj1q1bKyMjQ5L0yCOPaPr06W4tEAAAoCaoVCibMGGCdu7cqU2bNsnPz8/Z3r17dyUnJ7utOAAAgJrCuzI7rVmzRsnJyercubMcDoez/Xe/+53279/vtuIAAABqikqtlB07dkxNmjQp0X7q1CmXkAYAAIDyqVQou/7667Vu3Trn63NB7JVXXlFsbKx7KgMAAKhBKnX5MjExUXfccYd27dqlwsJCzZ07V//+97+1detWffLJJ+6uEQAA4LJXqZWyLl266PPPP9fp06cVFRWlDz/8UMHBwdq6datiYmLcXSMAAMBlr1IrZZLUtm1bLVu2zJ21AAAA1FjlDmV5eXnlHjQgIKBSxQAAANRU5Q5l9evXL/cnK4uKiipdEAAAQE1U7lC2ceNG58/p6ekaP368RowY4fy05datW7Vs2TIlJia6v0oAAIDLXLlD2U033eT8edq0aZo1a5YGDx7sbOvbt6/atm2rRYsWafjw4e6tEgAA4DJXqU9fbt26VR07dizR3rFjR23btq3KRQEAANQ0lQplYWFhWrBgQYn2hQsXKiwsrMpFAQAA1DSVeiTG7NmzNXDgQG3YsEGdO3eWJH3xxRfav3+/Vq1a5dYCAQAAaoJKrZT16tVL+/btU9++ffXjjz8qJydH/fr10969e9WrVy931wgAAHDZq/TDY5s1a6a//vWv7qwFAACgxqp0KJOk06dPKyMjQwUFBS7t1157bZWKAgAAqGkqFcqOHTumkSNH6v333y/1fR4eCwAAUDGVuqds7Nix+umnn/TFF1/I399fH3zwgZYtW6arr75a7733nrtrBAAAuOxVaqXs448/1t///nddf/31qlWrlsLDw3X77bcrICBAiYmJ6t27t7vrBAAAuKxVaqXs1KlTatKkiSSpYcOGOnbsmCSpbdu22rFjh/uqAwAAqCEqFcqio6O1Z88eSVL79u21cOFCZWZmasGCBQoNDXVrgQAAADVBpS5fjh07VllZWZKkyZMnq0ePHlqxYoV8fHy0dOlSd9YHAABQI1QqlN17773Onzt06KD09HR99913at68uYKCgtxWHAAAQE1RpeeUnVOnTh1dd9117hgKAACgRip3KBs3bly5B501a1aligEAAKipyh3KUlNTXV5v375dRUVFio6OliTt3btXXl5eiomJcW+FAAAANUC5Q9nGjRudP8+aNUtXXHGFli1bpgYNGkiSfvrpJ40cOVLdunVzf5UAAACXuUo9EmPmzJlKTEx0BjJJatCggZ599lnNnDnTbcUBAADUFJUKZXl5efrhhx9KtGdnZ+vkyZNVLgoAAKCmqVQoGzBggEaOHKl33nlHhw8f1uHDh/XOO+9o1KhRuuuuu9xdIwAAwGWvUo/EWLBggR5//HHdd999Onv27K8DeXtr1KhReuGFF9xaIAAAQE1QqVBWp04dzZs3Ty+88IL2798vY4xatGihunXrurs+AACAGqFKD4+tW7eurr32WnfVAgAAUGOVO5TdddddWrp0qQICAi5439jq1aurXBgAAEBNUu5QFhgYKIfD4fwZAAAA7lPuULZkyZJSfwYAAEDVVeqRGGfOnNHp06edrw8ePKg5c+boww8/dFthAAAANUmlQlm/fv20fPlySdKJEyd0ww03aObMmerXr5/mz5/v1gIBAABqgkqFsh07dji/4/Kdd95RSEiIDh48qOXLl+vFF1+s0Fjz5s1TZGSk/Pz8FBMTo82bN5fZ97PPPlPXrl3VqFEj+fv765prrtHs2bMrcwoAAABWqdQjMU6fPq0rrrhCkvThhx/qrrvuUq1atdS5c2cdPHiw3OMkJydr7Nixmjdvnrp27aqFCxeqZ8+e2rVrl5o3b16if926dfXwww/r2muvVd26dfXZZ5/pwQcfVN26dfXAAw9U5lQAAACsUKmVshYtWmjNmjU6dOiQNmzYoLi4OEm/fvdlQEBAuceZNWuWRo0apYSEBLVq1Upz5sxRWFhYmZdAO3TooMGDB6t169aKiIjQfffdpx49epx3dQ0AAOBSUKlQNmnSJD3++OOKiIhQp06dFBsbK+nXVbMOHTqUa4yCggJt377dGejOiYuL05YtW8o1RmpqqrZs2aKbbrqpzD75+fnKy8tz2QAAAGxTqcuXd999t37/+98rKytL7dq1c7bfdtttGjBgQLnGOH78uIqKihQcHOzSHhwcrKNHj55332bNmunYsWMqLCzUlClTlJCQUGbfxMRETZ06tVw1AQAAeEqlv2YpJCREISEhLm033HBDhcc590Dac4wxJdp+a/Pmzfr555/1xRdfaPz48WrRooUGDx5cat8JEyZo3Lhxztd5eXkKCwurcJ0AAAAXU6VC2alTpzR9+nR99NFHys7OVnFxscv733///QXHCAoKkpeXV4lVsezs7BKrZ78VGRkpSWrbtq1++OEHTZkypcxQ5uvrK19f3wvWAwAA4EmVCmUJCQn65JNPNHToUIWGhl5wZas0Pj4+iomJUUpKisslz5SUFPXr16/c4xhjlJ+fX+HjAwAA2KRSoez999/XunXr1LVr1yodfNy4cRo6dKg6duyo2NhYLVq0SBkZGRo9erSkXy89ZmZmOh9U+/LLL6t58+a65pprJP363LIZM2boT3/6U5XqAAAA8LRKhbIGDRqoYcOGVT54fHy8cnJyNG3aNGVlZalNmzZav369wsPDJUlZWVnKyMhw9i8uLtaECRN04MABeXt7KyoqStOnT9eDDz5Y5VoAAAA8yWGMMRXd6fXXX9ff//53LVu2THXq1LkYdV00eXl5CgwMVG5uboWeqQYAkhQxfp2nS6iy9Om9PV0CUKOUN3tUaqVs5syZ2r9/v4KDgxUREaHatWu7vL9jx47KDAsAAFBjVSqU9e/f381lAAAA1GyVCmWTJ092dx0AAAA1WqW+ZkmSTpw4oVdffVUTJkzQjz/+KOnXy5aZmZluKw4AAKCmqNRK2TfffKPu3bsrMDBQ6enp+uMf/6iGDRvq3Xff1cGDB52PsAAAAED5VGqlbNy4cRoxYoT27dsnPz8/Z3vPnj316aefuq04AACAmqJSoeyrr74q9dlgV1555QW/TBwAAAAlVSqU+fn5KS8vr0T7nj171Lhx4yoXBQAAUNNUKpT169dP06ZN09mzZyVJDodDGRkZGj9+vAYOHOjWAgEAAGqCSoWyGTNm6NixY2rSpInOnDmjm266SS1atNAVV1yh5557zt01AgAAXPYq9enLgIAAffbZZ9q4caO2b9+u4uJiXXfdderevbu76wMAAKgRKhzKiouLtXTpUq1evVrp6elyOByKjIxUSEiIjDFyOBwXo04AAIDLWoUuXxpj1LdvXyUkJCgzM1Nt27ZV69atdfDgQY0YMUIDBgy4WHUCAABc1iq0UrZ06VJ9+umn+uijj3TLLbe4vPfxxx+rf//+Wr58uYYNG+bWIgEAAC53FVopW7lypZ5++ukSgUySbr31Vo0fP14rVqxwW3EAAAA1RYVC2TfffKM77rijzPd79uypnTt3VrkoAACAmqZCoezHH39UcHBwme8HBwfrp59+qnJRAAAANU2FQllRUZG8vcu+Dc3Ly0uFhYVVLgoAAKCmqdCN/sYYjRgxQr6+vqW+n5+f75aiAAAAapoKhbLhw4dfsA+fvAQAAKi4CoWyJUuWXKw6AAAAarRKffclAAAA3ItQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFjA46Fs3rx5ioyMlJ+fn2JiYrR58+Yy+65evVq33367GjdurICAAMXGxmrDhg3VWC0AAMDF4dFQlpycrLFjx2rixIlKTU1Vt27d1LNnT2VkZJTa/9NPP9Xtt9+u9evXa/v27brlllvUp08fpaamVnPlAAAA7uUwxhhPHbxTp0667rrrNH/+fGdbq1at1L9/fyUmJpZrjNatWys+Pl6TJk0qV/+8vDwFBgYqNzdXAQEBlaobQM0VMX6dp0uosvTpvT1dAlCjlDd7eGylrKCgQNu3b1dcXJxLe1xcnLZs2VKuMYqLi3Xy5Ek1bNiwzD75+fnKy8tz2QAAAGzj7akDHz9+XEVFRQoODnZpDw4O1tGjR8s1xsyZM3Xq1Cndc889ZfZJTEzU1KlTq1Qr4GmszgDA5c/jN/o7HA6X18aYEm2lWblypaZMmaLk5GQ1adKkzH4TJkxQbm6uczt06FCVawYAAHA3j62UBQUFycvLq8SqWHZ2donVs99KTk7WqFGj9Pbbb6t79+7n7evr6ytfX98q1wsAAHAxeWylzMfHRzExMUpJSXFpT0lJUZcuXcrcb+XKlRoxYoTeeOMN9e7N5RAAAHB58NhKmSSNGzdOQ4cOVceOHRUbG6tFixYpIyNDo0ePlvTrpcfMzEwtX75c0q+BbNiwYZo7d646d+7sXGXz9/dXYGCgx84DAACgqjwayuLj45WTk6Np06YpKytLbdq00fr16xUeHi5JysrKcnlm2cKFC1VYWKiHHnpIDz30kLN9+PDhWrp0aXWXDwAA4DYeDWWSNGbMGI0ZM6bU934btDZt2nTxCwIAAPAAj3/6EgAAAIQyAAAAKxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAt4e7oAADVDxPh1ni4BAKzGShkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiA777EZY/vXARcXQ5/JtKn9/Z0CYDbsVIGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAW8PZ0AZeriPHrPF1ClaVP7+3pEgAAqDFYKQMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALODxUDZv3jxFRkbKz89PMTEx2rx5c5l9s7KyNGTIEEVHR6tWrVoaO3Zs9RUKAABwEXk0lCUnJ2vs2LGaOHGiUlNT1a1bN/Xs2VMZGRml9s/Pz1fjxo01ceJEtWvXrpqrBQAAuHg8GspmzZqlUaNGKSEhQa1atdKcOXMUFham+fPnl9o/IiJCc+fO1bBhwxQYGFiuY+Tn5ysvL89lAwAAsI3HQllBQYG2b9+uuLg4l/a4uDht2bLFbcdJTExUYGCgcwsLC3Pb2AAAAO7isVB2/PhxFRUVKTg42KU9ODhYR48eddtxJkyYoNzcXOd26NAht40NAADgLt6eLsDhcLi8NsaUaKsKX19f+fr6um08AACAi8FjK2VBQUHy8vIqsSqWnZ1dYvUMAADgcuexUObj46OYmBilpKS4tKekpKhLly4eqgoAAMAzPHr5cty4cRo6dKg6duyo2NhYLVq0SBkZGRo9erSkX+8Hy8zM1PLly537pKWlSZJ+/vlnHTt2TGlpafLx8dHvfvc7T5wCAACAW3g0lMXHxysnJ0fTpk1TVlaW2rRpo/Xr1ys8PFzSrw+L/e0zyzp06OD8efv27XrjjTcUHh6u9PT06iwdAADArTx+o/+YMWM0ZsyYUt9bunRpiTZjzEWuCAAAoPp5/GuWAAAAQCgDAACwAqEMAADAAoQyAAAACxDKAAAALODxT1/CXhHj13m6BAAoFX8/2SN9em9Pl3DZYKUMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMAADAAoQyAAAACxDKAAAALEAoAwAAsAChDAAAwAKEMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAs4O3pAgAAwKUrYvw6T5dQZenTe3u6BEmslAEAAFiBUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFiCUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABQhlAAAAFvB4KJs3b54iIyPl5+enmJgYbd68+bz9P/nkE8XExMjPz09XXXWVFixYUE2VAgAAXDweDWXJyckaO3asJk6cqNTUVHXr1k09e/ZURkZGqf0PHDigXr16qVu3bkpNTdXTTz+tRx55RKtWrarmygEAANzLYYwxnjp4p06ddN1112n+/PnOtlatWql///5KTEws0f+pp57Se++9p927dzvbRo8erZ07d2rr1q3lOmZeXp4CAwOVm5urgICAqp9EGSLGr7toYwMAAPdJn977oo5f3uzhfVGrOI+CggJt375d48ePd2mPi4vTli1bSt1n69atiouLc2nr0aOHkpKSdPbsWdWuXbvEPvn5+crPz3e+zs3NlfTrBF1MxfmnL+r4AADAPS52Jjg3/oXWwTwWyo4fP66ioiIFBwe7tAcHB+vo0aOl7nP06NFS+xcWFur48eMKDQ0tsU9iYqKmTp1aoj0sLKwK1QMAgMtF4JzqOc7JkycVGBhY5vseC2XnOBwOl9fGmBJtF+pfWvs5EyZM0Lhx45yvi4uL9eOPP6pRo0bnPU5V5OXlKSwsTIcOHbqol0gvd8yjezCP7sNcugfz6B7Mo3tUxzwaY3Ty5Ek1bdr0vP08FsqCgoLk5eVVYlUsOzu7xGrYOSEhIaX29/b2VqNGjUrdx9fXV76+vi5t9evXr3zhFRAQEMAfFDdgHt2DeXQf5tI9mEf3YB7d42LP4/lWyM7x2KcvfXx8FBMTo5SUFJf2lJQUdenSpdR9YmNjS/T/8MMP1bFjx1LvJwMAALhUePSRGOPGjdOrr76qxYsXa/fu3Xr00UeVkZGh0aNHS/r10uOwYcOc/UePHq2DBw9q3Lhx2r17txYvXqykpCQ9/vjjnjoFAAAAt/DoPWXx8fHKycnRtGnTlJWVpTZt2mj9+vUKDw+XJGVlZbk8sywyMlLr16/Xo48+qpdffllNmzbViy++qIEDB3rqFErl6+uryZMnl7hsiophHt2DeXQf5tI9mEf3YB7dw6Z59OhzygAAAPArj3/NEgAAAAhlAAAAViCUAQAAWIBQBgAAYAFCWRWcPHlSY8eOVXh4uPz9/dWlSxd99dVXzvdXr16tHj16KCgoSA6HQ2lpaZ4r1mLnm8ezZ8/qqaeeUtu2bVW3bl01bdpUw4YN05EjRzxctX0u9Ps4ZcoUXXPNNapbt64aNGig7t2768svv/Rgxfa60Fz+twcffFAOh0Nz5syp3iIvAReaxxEjRsjhcLhsnTt39mDFdirP7+Pu3bvVt29fBQYG6oorrlDnzp1dnl6AC8/jb38Xz20vvPBCtdVIKKuChIQEpaSk6LXXXtO3336ruLg4de/eXZmZmZKkU6dOqWvXrpo+fbqHK7Xb+ebx9OnT2rFjh5555hnt2LFDq1ev1t69e9W3b19Pl22dC/0+tmzZUi+99JK+/fZbffbZZ4qIiFBcXJyOHTvm4crtc6G5PGfNmjX68ssvL/jVKTVVeebxjjvuUFZWlnNbv369Byu204Xmcf/+/fr973+va665Rps2bdLOnTv1zDPPyM/Pz8OV2+VC8/jfv4dZWVlavHixHA5H9T52y6BSTp8+bby8vMzatWtd2tu1a2cmTpzo0nbgwAEjyaSmplZjhZeGiszjOdu2bTOSzMGDB6ujxEtCZeYxNzfXSDL//Oc/q6PES0Z55/Lw4cPmyiuvNP/6179MeHi4mT17djVXarfyzOPw4cNNv379PFDdpaM88xgfH2/uu+8+T5R3yajM35H9+vUzt956a3WU58RKWSUVFhaqqKioxP+J+Pv767PPPvNQVZeeysxjbm6uHA5HtX2H6aWgovNYUFCgRYsWKTAwUO3atauuMi8J5ZnL4uJiDR06VE888YRat27tiTKtV97fyU2bNqlJkyZq2bKl/vjHPyo7O7u6S7XaheaxuLhY69atU8uWLdWjRw81adJEnTp10po1azxTsKUq+nfkDz/8oHXr1mnUqFHVVeKvqjUCXmZiY2PNTTfdZDIzM01hYaF57bXXjMPhMC1btnTpx0rZ+ZV3Ho0x5syZMyYmJsbce++9HqjUbuWZx3/84x+mbt26xuFwmKZNm5pt27Z5sGJ7XWgu//rXv5rbb7/dFBcXG2MMK2VluNA8vvnmm2bt2rXm22+/Ne+9955p166dad26tfnll188XLldzjePWVlZRpKpU6eOmTVrlklNTTWJiYnG4XCYTZs2ebp0q1Tk35rnn3/eNGjQwJw5c6ZaaySUVcF//vMfc+ONNxpJxsvLy1x//fXm3nvvNa1atXLpRyg7v/LOY0FBgenXr5/p0KGDyc3N9VC19irPPP78889m3759ZuvWreb+++83ERER5ocffvBg1XY631x+/fXXJjg42GRmZjr7E8pKV94/2+ccOXLE1K5d26xataqaK7Xb+eYxMzPTSDKDBw922adPnz5m0KBBHqrYThX5fYyOjjYPP/xwtdfI5csqiIqK0ieffKKff/5Zhw4d0rZt23T27FlFRkZ6urRLSnnm8ezZs7rnnnt04MABpaSkKCAgwIMV26k881i3bl21aNFCnTt3VlJSkry9vZWUlOTBqu10vrncvHmzsrOz1bx5c3l7e8vb21sHDx7UY489poiICE+XbpWK/h0ZGhqq8PBw7du3r5ortdv55jEoKEje3t763e9+57JPq1at+PTlb5T393Hz5s3as2ePEhISqr1GQpkb1K1bV6Ghofrpp5+0YcMG9evXz9MlXZLKmsdzgWzfvn365z//qUaNGnm4UrtV5PfRGKP8/PxqrO7SUtpcDh06VN98843S0tKcW9OmTfXEE09ow4YNni7ZSuX9nczJydGhQ4cUGhpazRVeGkqbRx8fH11//fXas2ePS9+9e/cqPDzcQ5Xa7UK/j0lJSYqJifHI/bbe1X7Ey8iGDRtkjFF0dLT+85//6IknnlB0dLRGjhwpSfrxxx+VkZHhfKbWuT80ISEhCgkJ8VjdtjnfPBYWFuruu+/Wjh07tHbtWhUVFeno0aOSpIYNG8rHx8fD1dvjfPN46tQpPffcc+rbt69CQ0OVk5OjefPm6fDhw/rDH/7g6dKtc765rF27don/Mahdu7ZCQkIUHR3toYrtdL55/PnnnzVlyhQNHDhQoaGhSk9P19NPP62goCANGDDA06Vb5UL/1jzxxBOKj4/XjTfeqFtuuUUffPCB/vGPf2jTpk2eLdwyF5pHScrLy9Pbb7+tmTNneqbIar9gehlJTk42V111lfHx8TEhISHmoYceMidOnHC+v2TJEiOpxDZ58mTPFW2h883jufvxSts2btzo2cItc755PHPmjBkwYIBp2rSp8fHxMaGhoaZv377c6F+GC/3Z/i3uKSvd+ebx9OnTJi4uzjRu3NjUrl3bNG/e3AwfPtxkZGR4uGr7lOf3MSkpybRo0cL4+fmZdu3amTVr1nioWnuVZx4XLlxo/P39z/vn/WJyGGOMZ+IgAAAAzuGeMgAAAAsQygAAACxAKAMAALAAoQwAAMAChDIAAAALEMoAAAAsQCgDAACwAKEMACpo4cKF+uSTTzxdBoDLDKEMACrg9ddf1yuvvKKOHTuWe5/09HQ5HA6lpaVdvMIAXPIIZQAuOVu2bJGXl5fuuOOOaj3uvn379Pzzz2vdunWqW7duufcLCwtTVlaW2rRpcxGrA3Cp42uWAFxyEhISVK9ePb366qvatWuXmjdvftGOdfbsWdWuXfuijQ8A57BSBuCScurUKb311lv6n//5H915551aunSpy/vvvfeeOnbsKD8/PwUFBemuu+5yvudwOLRmzRqX/vXr13eOce4y41tvvaWbb75Zfn5+ev3115WTk6PBgwerWbNmqlOnjtq2bauVK1e6jFNcXKznn39eLVq0kK+vr5o3b67nnnvOZdxzly+Lioo0atQoRUZGyt/fX9HR0Zo7d67LeJs2bdINN9ygunXrqn79+uratasOHjxY9QkEYC1CGYBLSnJysqKjoxUdHa377rtPS5Ys0bkF/3Xr1umuu+5S7969lZqaqo8++qhC936d89RTT+mRRx7R7t271aNHD505c0YdOnTQ2rVr9e233yohIUH33XefvvzyS+c+EyZM0PPPP69nnnlGu3bt0htvvKHg4OBSxy8uLlazZs301ltvadeuXZo0aZKefvppvfXWW5KkwsJC9e/fXzfddJO++eYbbd26VQ888IAcDkclZgzAJcMAwCWkS5cuZs6cOcYYY86ePWuCgoJMSkqKMcaY2NhYc++995a5ryTz7rvvurQFBgaaJUuWGGOMOXDggJHkHP987rjjDvPYY48ZY4zJy8szvr6+5pVXXim177lxU1NTyxxvzJgxZuDAgcYYY3Jycowks2nTpgvWAeDywUoZgEvGnj17tG3bNg0aNEiS5O3trfj4eC1evFiSlJaWpttuu63Kx/nt6lpxcbFmz56t2NhYNW/eXCEhIdq0aZMyMjIkSbt371Z+fn6Fjr1gwQJ17NhRjRs3Vr169fTKK684x2vYsKFGjBihHj16qE+fPpo7d66ysrKqfF4A7EYoA3DJSEpKUmFhoa688kp5e3vL29tb8+fP1+rVq/XTTz/J39//vPs7HA7npc5zzp49W6Lfbz9ZOWfOHE2fPl1PPfWUNm7cqLS0NMXFxamgoECSLnjc33rrrbf06KOP6v7779eHH36otLQ0jRw50jmeJC1ZskRbt25Vly5dlJycrJYtW+qLL76o0HEAXFoIZQAuCYWFhVq+fLlmzpyptLQ057Zz506Fh4drxYoVuvbaa/XRRx+VOUbjxo1dVpz27dun06dPX/DYGzduVJ8+fdS/f39FRUWpcePG2rVrl/P9q6++Wv7+/uc99n/bvHmzunTpojFjxqhDhw5q0aKF9u/fX6Jfhw4dNGHCBG3ZskVt2rTRG2+8Ua7xAVyavD1dAACUx9q1a/XTTz9p1KhRCgwMdHnv7rvvVlJSkmbPnq3bbrtNUVFRGjRokAoLC/X+++/rySeflCTdeuuteumll9S5c2cVFxfrqaeeKtfjLqKiorRq1Spt2bJF9evX18yZM5Wdna3WrVtLkvz8/PTUU0/pySeflI+Pj7p27apjx47p3//+t0aNGlVivBYtWmj58uXasGGDIiMj9dprr+mrr75SZGSkJOnAgQNatGiR+vbtq6ZNm2rPnj3au3evhg0bVtVpBGAxVsoAXBKSkpLUvXv3EoFMkgYOHKi0tDQFBATo7bff1nvvvaf27dvr1ltvdfmE5MyZMxUWFqYbb7xRQ4YM0eOPP646depc8NiTJk1STEyMevTooVtuuUVNmzZV//79Xfo888wzeuyxxzRp0iS1atVK8fHxys7OLnW80aNH66677lJ8fLw6deqknJwcjRkzxvl+nTp19N1332ngwIFq2bKlHnjgAT388MN68MEHyzlbAC5FPDwWAADAAqyUAQAAWIBQBgAAYAFCGQAAgAUIZQAAABYglAEAAFiAUAYAAGABQhkAAIAFCGUAAAAWIJQBAABYgFAGAABgAUIZAACABf4PkXwcsk4h3ncAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando um histograma para visualizar melhor a distribuição das acurácias\n",
    "# Definindo a figura\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plotando o gráfico\n",
    "plt.subplot(111)\n",
    "plt.hist(acuracia_100, density=True)\n",
    "plt.xlabel(\"Acurácias\")\n",
    "plt.ylabel(\"Densidade\")\n",
    "plt.title(\"Análise das acurácias\")\n",
    "\n",
    "# Mostrando o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão:\n",
    "    Em suma, pode-se notar que o classificador, no geral obtve uma acurácia alta, com média de 93,77%, porém sua mediana foi de 94,00%, sendo assim a maioria dos resultados estão acima da média (assim como se observa no histograma), algo muito interessante para a empresa visto que apesar da simplicidade do classificador, ele entregou resultados melhores do que o esperado, dessa maneira, com mais investimento no projeto, será possível incrementar novos mecanismos de limpeza de mensagens, assim como de aumentar a base de dados.\n",
    "\n",
    "    Em relação aos valores que se encontram abaixo do primeiro qualtil (de 91% a 93%), uma justificativa para possuirem uma precisão menor em relação ao resto deve-se ao fato de que os dados de treinamento foram sorteados 100 diferentes vezes, e em algumas delas a diferença de comentários relevantes e irrelevantes deve ter sido muito ampla, possuindo muios comentários de só um target, o que induz um maior erro no classificador, pois haverá muitas palavras a mais em uma classe do que na outra, dessa forma a probabilidade de uma palavra pertercenr a classe com um maior numero de dados é maior do que pertercer a outra.\n",
    "\n",
    "    Da mesma maneira que os resultados pertencentes ao terceiro quartil (95% a 97%) possuem uma coletânea de treinamento muito bem sepearada, sendo a quantidade de cometários relevantes e irrelevantes aproximadamente a mesma, permitindo que o classificador avalie com mais propriedade um comentário, evitando classificações incorretas.\n",
    "\n",
    "    Portanto, construir um classificador baseado em somente uma única divisão da base de dados em treinamento e em teste pode ser um pouco arriscado, pois há chances dele possuir uma acurácia muito alta, assim como uma mais baixa. Porém, levando em consideração nossas informações, o desvio padrão dos dados de todas acurácias é consideravelmente baixo, de somento 1,35%, o que pode levar a acreditar que os riscos de dividir os dados em treino e teste uma única vez pode não ser muito grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e519a5cf2e8f0955561b2ee7ea69bac76367187692ae83f9e046badc6f67ca5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
